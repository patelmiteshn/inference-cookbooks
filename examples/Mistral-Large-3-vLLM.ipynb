{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d6d8420-ec0e-42ef-83fd-b06e98122246",
   "metadata": {},
   "source": [
    "# Running Mistral Large 3 675B Instruct with vLLM on NVIDIA GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82073801-7445-4322-ba93-6fba73353b12",
   "metadata": {},
   "source": [
    "**Authors:** [Katja Sirazitdinova](https://github.com/katjasrz), [Jay Rodge](https://github.com/jayrodge), [Mitesh Patel](https://github.com/patelmiteshn), Developer Advocates @ NVIDIA\n",
    "\n",
    "---\n",
    "\n",
    "This notebook provides a comprehensive guide on how to run the **Mistral Large 3 675B Instruct** model using vLLM. \n",
    "\n",
    "Mistral Large 3 is a state-of-the-art general-purpose multimodal granular Mixture-of-Experts model with 41B active parameters and 675B total parameters.\n",
    "\n",
    "This model is the instruct post-trained version, fine-tuned for instruction tasks, making it ideal for chat, agentic and instruction based use cases. Designed for reliability and long-context comprehension - it is engineered for production-grade assistants, retrieval-augmented systems, scientific workloads, and complex enterprise workflows.\n",
    "\n",
    "## Launch on NVIDIA Brev\n",
    "\n",
    "You can simplify the environment setup by using [NVIDIA Brev](https://developer.nvidia.com/brev). Click the button below to launch this project on a Brev instance with the necessary dependencies pre-configured.\n",
    "\n",
    "Once deployed, click on the \"Open Notebook\" button to get started with this guide.\n",
    "\n",
    "[![Launch on Brev](https://brev-assets.s3.us-west-1.amazonaws.com/nv-lb-dark.svg)](https://brev.nvidia.com/launchable/deploy?launchableID=env-36IT87VH89qYpkwYrouOUVWeNSK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af017c7c-c01e-45c3-9d31-875949354fb3",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [Prerequisites](#Prerequisites)\n",
    "  - [Verifying your system](#Verifying-your-system)\n",
    "  - [Installing vLLM](#Installing-vLLM)\n",
    "- [Launch OpenAI-compatible server](#Launch-OpenAI-compatible-server)\n",
    "- [Client setup](#Client-setup)\n",
    "- [Testing some scenarios](#Testing-some-scenarios)\n",
    "  - [Instruction following](#Instruction-following)\n",
    "  - [Vision reasoning](#Vision-reasoning)\n",
    "  - [Function calling](#Function-calling)\n",
    "- [Conclusion and resources](#Conclusion-and-resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f9c20-f562-4efc-98cf-beb9fb04401e",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4869f32-d2c1-45aa-9a42-72b1f8b5aac4",
   "metadata": {},
   "source": [
    "Mistral Large 3 is deployable on-premises at [FP8](https://huggingface.co/mistralai/Mistral-Large-3-675B-FP8-Instruct-2512) on a single node of B200 or H200 GPUs, with H200 having a reduced context window.\n",
    "\n",
    "This notebook is configured by default to run on a machine with 8 GPUs and sufficient VRAM to hold the 675B parameter model. If your hardware is different, be sure to adjust the `--tensor-parallel-size` (tensor parallelism) and other resource-related flags in the server launch command provided further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1598a8-aaf8-4005-9f73-24e732a451cb",
   "metadata": {},
   "source": [
    "### Verifying your system\n",
    "\n",
    "Let's verify your system is ready for **Mistral Large 3 675B Instruct**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17041a6d-52fa-4288-9eec-0682a913393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import subprocess\n",
    "import platform\n",
    "import shutil\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"=\"*70)\n",
    "print(f\"OS: {platform.system()} {platform.release()}\")\n",
    "print(f\"Python: {platform.python_version()}\")\n",
    "\n",
    "# Check if nvidia-smi exists\n",
    "if shutil.which(\"nvidia-smi\") is None:\n",
    "    print(\"‚ùå nvidia-smi not found ‚Äî NVIDIA drivers are missing or not in PATH.\")\n",
    "    print(\"   Unable to detect GPU hardware.\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GPU DETAILS (nvidia-smi)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Query GPU name + total memory\n",
    "    query_cmd = [\n",
    "        \"nvidia-smi\",\n",
    "        \"--query-gpu=name,memory.total\",\n",
    "        \"--format=csv,noheader,nounits\"\n",
    "    ]\n",
    "\n",
    "    output = subprocess.check_output(query_cmd, text=True)\n",
    "    lines = [line.strip() for line in output.splitlines() if line.strip()]\n",
    "    total_memory_gb = 0.0\n",
    "\n",
    "    print(f\"Number of GPUs detected: {len(lines)}\")\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        name, mem_mib = [x.strip() for x in line.split(\",\")]\n",
    "        mem_gb = float(mem_mib) / 1024\n",
    "        total_memory_gb += mem_gb\n",
    "\n",
    "        print(f\"\\nGPU[{i}]:\")\n",
    "        print(f\"  Name: {name}\")\n",
    "        print(f\"  Total Memory: {mem_gb:.2f} GB\")\n",
    "\n",
    "        if \"H200\" in name:\n",
    "            print(\"  Status: ‚úÖ Hopper architecture - Supported\")\n",
    "        elif \"B200\" in name or \"GB200\" in name:\n",
    "            print(\"  Status: ‚úÖ Blackwell architecture - Optimal\")\n",
    "        else:\n",
    "            print(\"  Status: ‚ö†Ô∏è Unknown/older architecture ‚Äî May have limitations\")\n",
    "\n",
    "    print(f\"\\nTotal GPU Memory (All GPUs): {total_memory_gb:.2f} GB\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Failed to parse GPU info from nvidia-smi\")\n",
    "    print(e)\n",
    "    exit(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NVLINK STATUS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    nvlink = subprocess.check_output([\"nvidia-smi\", \"nvlink\", \"--status\"],\n",
    "                                     text=True, stderr=subprocess.STDOUT)\n",
    "    print(\"‚úÖ NVLink detected & queryable\\n\")\n",
    "    print(nvlink.strip())\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è NVLink not detected or unavailable\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFIGURATION RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if total_memory_gb >= 1100:\n",
    "    print(\"‚úÖ Enough VRAM for large models ‚Äî recommended EP/DP execution\")\n",
    "elif total_memory_gb >= 900:\n",
    "    print(\"‚ö†Ô∏è Borderline for largest models ‚Äî FP8 or TP recommended\")\n",
    "elif total_memory_gb > 0:\n",
    "    print(\"‚ùå VRAM too low for full-size models ‚Äî use smaller/quantized checkpoints\")\n",
    "else:\n",
    "    print(\"‚ùå No GPUs detected ‚Äî GPU is required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e1603-2acd-45f5-936a-460bf89c98f9",
   "metadata": {},
   "source": [
    "### Installing vLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8138f525-9522-4192-8a60-1d83c62a8232",
   "metadata": {},
   "source": [
    "Install the latest vLLM nightly build with the Mistral backends enabled so you get the Blackwell kernels and MoE optimizations required for this checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97020e0e-b824-4d96-9f04-f439fce3f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -U vllm --torch-backend=auto --extra-index-url https://wheels.vllm.ai/nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a1798-643b-407d-ab20-169ca5b2dc78",
   "metadata": {},
   "source": [
    "Doing so should automatically install [`mistral_common >= 1.8.6`](https://github.com/mistralai/mistral-common/releases/tag/v1.8.6).\n",
    "\n",
    "To verify the version: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4d7a2-9d33-41a9-bc15-001f99a9cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mistral_common; print(mistral_common.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d744f02-bfff-4677-ac89-7d34df8f716b",
   "metadata": {},
   "source": [
    "You can also make use of a ready-to-go [docker image](https://github.com/vllm-project/vllm/blob/main/Dockerfile) or on the [docker hub](https://hub.docker.com/layers/vllm/vllm-openai/latest/images/sha256-de9032a92ffea7b5c007dad80b38fd44aac11eddc31c435f8e52f3b7404bbf39)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c32ace-15c1-491a-9ffe-6ba14c7e4039",
   "metadata": {},
   "source": [
    "## Launch OpenAI-compatible server\n",
    "\n",
    "When launching an OpenAI-compatible server, the exact configuration you use should depend heavily on the hardware available in your cluster and the level of model quantization you choose. Different GPUs and memory budgets will favor different precision settings and kernel implementations. In particular, high-end setups with multiple B200 GPUs can push for more aggressive optimizations like FP8 to maximize throughput without sacrificing too much quality.\n",
    "\n",
    "Below are example configurations optimized for different setups. Run them in a terminal window.\n",
    "\n",
    "Set the `\"$MODEL\"` variable to one of the official checkpoints published by Mistral so the launch commands pull the right weights:\n",
    "\n",
    "- `mistralai/Mistral-Large-3-675B-Instruct-2512` (FP8, recommended for B200/H200)\n",
    "- `mistralai/Mistral-Large-3-675B-Instruct-2512-NVFP4` (NVFP4 for H100/A100)\n",
    "- `mistralai/Mistral-Large-3-675B-Instruct-2512-BF16` (full precision for fidelity testing)\n",
    "- `mistralai/Mistral-Large-3-675B-Instruct-2512-Eagle` (draft model for speculative decoding)\n",
    "\n",
    "You can also initialize it as a path to the model if you have it downloaded locally:\n",
    "\n",
    "```bash\n",
    "MODEL_PATH=\"/path/to/the/model\"\n",
    "```\n",
    "\n",
    "#### FP8 on 8xB200\n",
    "\n",
    "On an 8√óB200 node, we can safely run the model in FP8 to squeeze out significantly higher effective throughput and better hardware utilization. \n",
    "\n",
    "* We rely on FlashInfer kernels for both the Multi-Head Latent Attention (MLA) path and the Mixture-of-Experts (MoE) layers in FP8. These kernels are optimized for modern NVIDIA architectures and are designed to reduce latency and improve tokens-per-second, especially at larger batch sizes and longer context lengths.\n",
    "\n",
    "* The key‚Äìvalue (KV) cache is also kept in FP8 format. This drastically cuts memory consumption for long-context inference and allows the model to handle more concurrent requests or longer sequences without running out of GPU memory. The trade-off in numerical precision is usually minimal for inference workloads, while the performance gain is substantial.\n",
    "\n",
    "Overall, this FP8 + FlashInfer configuration is aimed at high-throughput, production-grade serving on 8√óB200, where the priority is maximizing utilization and request throughput while still maintaining acceptable response quality.\n",
    "\n",
    "```bash\n",
    "VLLM_ATTENTION_BACKEND=FLASHINFER_MLA \\\n",
    "VLLM_USE_FLASHINFER_MOE_FP8=1 \\\n",
    "VLLM_FLASHINFER_MOE_BACKEND=latency \\\n",
    "vllm serve \"$MODEL\" \\\n",
    "  --load-format mistral \\\n",
    "  --tokenizer-mode mistral \\\n",
    "  --config-format mistral \\\n",
    "  --max_model_len 65536 \\\n",
    "  --max_num_seqs 128 \\\n",
    "  --tensor-parallel-size 8 \\\n",
    "  --enable-auto-tool-choice \\\n",
    "  --tool-call-parser mistral \\\n",
    "  --limit-mm-per-prompt '{\"image\":10}' \\\n",
    "  --kv-cache-dtype fp8 \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 8000\n",
    "```\n",
    "\n",
    "#### NVFP4 on 8xB200\n",
    "\n",
    "This configuration uses FlashInfer for MLA while switching MoE layers to NVFP4, a format optimized for NVIDIA architectures that provides a tighter balance between efficiency and output quality compared to raw FP8. NVFP4 reduces memory footprint substantially, allowing high batch concurrency and long-context serving without hitting capacity ceilings.\n",
    "\n",
    "MLA operations run on FlashInfer for fast attention kernels, and MoE experts are quantized to NVFP4. This keeps expert computation light without a critical loss in fidelity, making this option well-suited for heavy MoE workloads or cost-sensitive production environments. Keeping the KV cache in FP8 further reduces memory pressure.\n",
    "\n",
    "The result is a configuration that hits a sweet spot between speed, memory, and response quality.\n",
    "\n",
    "```bash\n",
    "VLLM_ATTENTION_BACKEND=FLASHINFER_MLA \\\n",
    "VLLM_USE_FLASHINFER_MOE_FP4=1 \\\n",
    "VLLM_FLASHINFER_MOE_BACKEND=latency \\\n",
    "vllm serve \"$MODEL\" \\\n",
    "  --load-format mistral \\\n",
    "  --tokenizer-mode mistral \\\n",
    "  --config-format mistral \\\n",
    "  --max_model_len 65536 \\\n",
    "  --max_num_seqs 128 \\\n",
    "  --tensor-parallel-size 8 \\\n",
    "  --enable-auto-tool-choice \\\n",
    "  --tool-call-parser mistral \\\n",
    "  --limit-mm-per-prompt '{\"image\":10}' \\\n",
    "  --kv-cache-dtype fp8 \\\n",
    "  --quantization modelopt_fp4 \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 8000\n",
    "```\n",
    "\n",
    "#### BF16 on 8xB200\n",
    "\n",
    "Running in full BF16 precision gives the highest numeric stability and preserves model quality, but it is considerably more memory-hungry than FP8 or FP4 variants. On an 8√óB200 configuration, the model fits ‚Äî but just barely ‚Äî so the serving parameters need to be tightened to stay within the VRAM budget.\n",
    "\n",
    "* Reduced max context length. The maximum sequence length is pulled down to avoid buffer overflow during sustained or concurrent inference.\n",
    "\n",
    "* GPU memory utilization up to 0.95. Increasing utilization ensures the GPUs are driven close to their physical limit.\n",
    "\n",
    "This mode is ideal if you want maximum output fidelity and training-like precision, and you're willing to trade off context length and system elasticity for it.\n",
    "\n",
    "```bash\n",
    "vllm serve \"$MODEL\" \\\n",
    "  --load-format mistral \\\n",
    "  --tokenizer-mode mistral \\\n",
    "  --config-format mistral \\\n",
    "  --max_model_len 32786 \\\n",
    "  --max_num_seqs 128 \\\n",
    "  --tensor-parallel-size 8 \\\n",
    "  --enable-auto-tool-choice \\\n",
    "  --tool-call-parser mistral \\\n",
    "  --limit-mm-per-prompt '{\"image\":10}' \\\n",
    "  --gpu-memory-utilization=0.95 \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 8000\n",
    "```\n",
    "\n",
    "The first startup might take long time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b1433a-83a8-4ad1-8f3a-ad2018fa03b2",
   "metadata": {},
   "source": [
    "## Client setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abc6d2-7a68-4ba5-81e1-9b3c7c84ac02",
   "metadata": {},
   "source": [
    "Once the server is running, connect using the OpenAI Python client. The endpoint exposes an OpenAI-compatible interface, so the standard OpenAI Python client will work without any additional adapters or client-side modifications. You simply point the client to your local server URL and provide the API key expected by vLLM (it can be any non-empty string unless you explicitly enforce authentication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a96029a-d542-4f84-a06e-d05d33cd20d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to vLLM server at http://127.0.0.1:8000\n",
      "Using model: mistralai/Mistral-Large-3-675B-Instruct-2512\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Connect to vLLM server\n",
    "client = OpenAI(\n",
    "    base_url=\"http://127.0.0.1:8000/v1\",\n",
    "    api_key=\"dummy\"  # vLLM doesn't require a real API key\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"mistral-ml3\"\n",
    "\n",
    "print(f\"Connected to vLLM server at http://127.0.0.1:8000\")\n",
    "print(f\"Using model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3b4f0-6bd4-47c5-82d0-daa3a595dcae",
   "metadata": {},
   "source": [
    "## Testing some scenarios\n",
    "\n",
    "According to its authors, Mistral Large 3 is perfect for:\n",
    "\n",
    "* Long document understanding\n",
    "* Daily-driver AI assistants\n",
    "* Agentic and tool-use capabilities\n",
    "* Enterprise knowledge work\n",
    "* General coding assistant\n",
    "\n",
    "Let's test some of its features!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d213595-a363-407f-b4fc-7ec0d1bc80c7",
   "metadata": {},
   "source": [
    "### Instruction following\n",
    "\n",
    "To guide the model toward a specific behavior or response style, you can supply a system prompt that defines rules, tone, formatting expectations, and constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ffe71c38-9c16-4fb3-b279-ccdc5a606c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's think about this. I need to invent a fun board game and explain the rules in under 120 words. First, I should think of a theme. Maybe something adventurous, like exploring a jungle or a space mission. But to keep it simple, perhaps a treasure hunt theme would work well.\n",
      "\n",
      "Next, I need to think about the mechanics. Maybe players move around the board collecting items or solving puzzles to find the treasure. But to make it unique, perhaps there's a twist, like having to avoid traps or compete with other players.\n",
      "\n",
      "Let's go with a treasure hunt theme. Players start at the base camp and move around the board collecting treasure maps. Each map leads to a different part of the board where treasure is hidden. But there are traps and obstacles that can set players back.\n",
      "\n",
      "Now, to write the rules concisely:\n",
      "\n",
      "1. Players start at the base camp.\n",
      "2. On their turn, players roll the die and move their piece.\n",
      "3. Land on a treasure map space to collect a map.\n",
      "4. Use maps to find treasure, but watch out for traps!\n",
      "5. First player to collect all treasures and return to base camp wins.\n",
      "\n",
      "But that's a bit vague. Let's make it more specific and fun.\n",
      "\n",
      "How about this:\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Be the first to collect all three treasures and return to base camp.\n",
      "\n",
      "Setup: Place the board on the table. Each player chooses a token and places it on the base camp. Shuffle the treasure cards and place them face down on the designated spaces.\n",
      "\n",
      "Rules:\n",
      "1. On your turn, roll the die and move your token.\n",
      "2. Land on a treasure map space to draw a map card. Follow the instructions to find a treasure.\n",
      "3. Land on a trap space to lose a turn or move back.\n",
      "4. Collect all three treasures and return to base camp to win!\n",
      "\n",
      "But that's a bit over 120 words. Let's try to condense it.\n",
      "\n",
      "**Treasure Hunt**\n",
      "\n",
      "Players race to collect 3 treasures and return to base. Roll die to move. Land on maps to find treasures, but traps slow you down. First to collect all treasures and return wins!\n",
      "\n",
      "That's 28 words. But maybe too brief. Let's try to add a bit more detail while keeping it under 120 words.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three treasures and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token.\n",
      "2. Land on map space: draw a map, move to treasure location.\n",
      "3. Land on trap: lose a turn or move back.\n",
      "4. Collect all treasures and return to base camp to win!\n",
      "\n",
      "That's 50 words. Still under 120. Maybe add a bit more flavor.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Be the first to collect all three treasures and return to base camp.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token.\n",
      "2. Land on map space: draw a map, move to treasure location to collect it.\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all treasures and return to base camp wins!\n",
      "\n",
      "That's 60 words. Still under 120. Maybe add a bit more about the board.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three treasures and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token.\n",
      "2. Land on map space: draw a map, move to treasure location to collect it.\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all treasures and return to base camp wins!\n",
      "\n",
      "That's 65 words. Still under 120. Maybe add a bit more about the treasures.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three unique treasures (gold, gem, artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token.\n",
      "2. Land on map space: draw a map, move to treasure location to collect it.\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all three treasures and return to base camp wins!\n",
      "\n",
      "That's 70 words. Still under 120. Maybe add a bit more about the movement.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three unique treasures (gold, gem, artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction.\n",
      "2. Land on map space: draw a map, move to treasure location to collect it.\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all three treasures and return to base camp wins!\n",
      "\n",
      "That's 75 words. Still under 120. Maybe add a bit more about the treasure collection.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three unique treasures (gold, gem, artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction.\n",
      "2. Land on map space: draw a map, move to treasure location to collect it (place treasure token on your board).\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all three treasures and return to base camp wins!\n",
      "\n",
      "That's 80 words. Still under 120. Maybe add a bit more about the win condition.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three unique treasures (gold, gem, artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction.\n",
      "2. Land on map space: draw a map, move to treasure location to collect it (place treasure token on your board).\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all three treasures and land on base camp wins!\n",
      "\n",
      "That's 85 words. Still under 120. Maybe add a bit more about the board layout.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three unique treasures (gold, gem, artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces around the board.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction.\n",
      "2. Land on map space: draw a map, move to treasure location to collect it (place treasure token on your board).\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all three treasures and land on base camp wins!\n",
      "\n",
      "That's 90 words. Still under 120. Maybe add a bit more about the treasures.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three unique treasures (gold coin, rare gem, ancient artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces around the board.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction.\n",
      "2. Land on map space: draw a map, move to treasure location to collect it (place treasure token on your board).\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all three treasures and land on base camp wins!\n",
      "\n",
      "That's 95 words. Still under 120. Maybe add a bit more about the movement.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three unique treasures (gold coin, rare gem, ancient artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces around the board.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction (forward, backward, sideways).\n",
      "2. Land on map space: draw a map, move to treasure location to collect it (place treasure token on your board).\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all three treasures and land on base camp wins!\n",
      "\n",
      "That's 100 words. Still under 120. Maybe add a bit more about the traps.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three unique treasures (gold coin, rare gem, ancient artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces around the board.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction (forward, backward, sideways).\n",
      "2. Land on map space: draw a map, move to treasure location to collect it (place treasure token on your board).\n",
      "3. Land on trap: choose to lose a turn or move back 3 spaces.\n",
      "4. First to collect all three treasures and land on base camp wins!\n",
      "\n",
      "That's 105 words. Still under 120. Maybe add a bit more about the win condition.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three unique treasures (gold coin, rare gem, ancient artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces around the board.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction (forward, backward, sideways).\n",
      "2. Land on map space: draw a map, move to treasure location to collect it (place treasure token on your board).\n",
      "3. Land on trap: choose to lose a turn or move back 3 spaces.\n",
      "4. First to collect all three treasures and land exactly on base camp wins!\n",
      "\n",
      "That's 110 words. Still under 120. Maybe add a bit more about the treasures.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three unique treasures (gold coin, rare gem, ancient artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down on map spaces around the board.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction (forward, backward, sideways).\n",
      "2. Land on map space: draw a map, move to treasure location to collect it (place treasure token on your board).\n",
      "3. Land on trap: choose to lose a turn or move back 3 spaces.\n",
      "4. First to collect all three treasures and land exactly on base camp with an exact roll wins!\n",
      "\n",
      "That's 115 words. Still under 120. Maybe that's enough.\n",
      "\n",
      "But perhaps the game could be more unique. Maybe instead of treasures, it's about collecting ingredients for a potion or something.\n",
      "\n",
      "Let's try another idea.\n",
      "\n",
      "**Potion Master**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Be the first to collect all five ingredients and brew the potion.\n",
      "\n",
      "Setup: Place tokens on start. Shuffle ingredient cards and place face down.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token.\n",
      "2. Land on ingredient space: draw a card, collect ingredient.\n",
      "3. Land on obstacle: lose a turn or move back.\n",
      "4. First to collect all ingredients and return to cauldron wins!\n",
      "\n",
      "That's 50 words. Maybe add more detail.\n",
      "\n",
      "**Potion Master**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all five unique ingredients (eye of newt, bat wing, etc.) and return to the cauldron first.\n",
      "\n",
      "Setup: Place tokens on start. Shuffle ingredient cards and place face down on ingredient spaces.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token.\n",
      "2. Land on ingredient space: draw a card, collect ingredient (place on your board).\n",
      "3. Land on obstacle: lose a turn or move back 2 spaces.\n",
      "4. First to collect all ingredients and land on cauldron wins!\n",
      "\n",
      "That's 70 words. Still under 120.\n",
      "\n",
      "But perhaps the first idea is better. Let's stick with Treasure Hunt Adventure and make sure it's under 120 words.\n",
      "\n",
      "**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three treasures (gold, gem, artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction.\n",
      "2. Land on map: draw a map, move to treasure to collect it.\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all treasures and return to base camp wins!\n",
      "\n",
      "That's 60 words. Perfect!**Treasure Hunt Adventure**\n",
      "\n",
      "Players: 2-4\n",
      "Objective: Collect all three treasures (gold, gem, artifact) and return to base camp first.\n",
      "\n",
      "Setup: Place tokens on base camp. Shuffle treasure maps and place face down.\n",
      "\n",
      "Rules:\n",
      "1. Roll die, move token in any direction.\n",
      "2. Land on map: draw a map, move to treasure to collect it.\n",
      "3. Land on trap: lose a turn or move back 3 spaces.\n",
      "4. First to collect all treasures and return to base camp wins!\n",
      "\n",
      "(Word count: 60)\n"
     ]
    }
   ],
   "source": [
    "def load_system_prompt(filename: str) -> str:\n",
    "    with open(filename, \"r\") as file:\n",
    "        system_prompt = file.read()\n",
    "    return system_prompt\n",
    "\n",
    "TEMP = 0.15\n",
    "MAX_TOK = 100000\n",
    "SYSTEM_PROMPT = load_system_prompt(\"SYSTEM_PROMPT.txt\")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": \"Invent a fun board game and explain the rules in under 120 words.\"}\n",
    "    ],\n",
    "    temperature=TEMP,\n",
    "    max_tokens=MAX_TOK,\n",
    ")\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b04c7e-8f69-430c-830b-76d7601d46b1",
   "metadata": {},
   "source": [
    "### Vision reasoning\n",
    "\n",
    "Vision reasoning refers to the model‚Äôs ability to interpret visual inputs and apply logical inference on top of what it sees ‚Äî not just recognizing objects, but understanding relationships, spatial context, cause-and-effect, and intent within an image. Instead of simply labelling elements, the model can describe scenes, infer actions, identify patterns, and answer questions that require comprehension rather than pattern-matching alone. This enables more advanced use cases such as analyzing diagrams, extracting information from charts, interpreting UI layouts, or evaluating photos for consistency and meaning. In short, vision reasoning bridges visual perception and conceptual understanding, allowing the model to think about images rather than merely see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "be253030-b72f-4022-abb5-1d82e799d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the image shows a cluttered workshop or studio filled with various tools, materials, and objects. It looks like an artist's or sculptor's workspace. There are busts, tools, jars with brushes, and lots of other items scattered around.\n",
      "\n",
      "Now, I need to think of an unusual scenario that could happen next in this scene. Let's brainstorm some ideas:\n",
      "\n",
      "1. **Unexpected Visitor**: Maybe a curious creature, like a small animal or even a mythical being, enters the workshop. Perhaps a raccoon starts rummaging through the materials, or a tiny dragon begins to play with the tools.\n",
      "\n",
      "2. **Magical Transformation**: The objects in the workshop could start to come to life. The busts might start talking, the tools could begin moving on their own, and the materials could start forming into new shapes.\n",
      "\n",
      "3. **Time Travel**: The artist might discover an old device or artifact in the workshop that allows them to travel through time. They could end up in a different era, bringing back unique items or ideas.\n",
      "\n",
      "4. **Art Heist**: A mysterious figure could sneak into the workshop to steal a valuable piece of art or an ancient artifact hidden among the clutter. The artist might have to solve a puzzle or riddle to protect their work.\n",
      "\n",
      "5. **Natural Phenomenon**: A sudden and unusual natural event could occur, like a small tornado or a beam of light from the sky, causing the objects in the workshop to levitate or rearrange themselves in a surprising way.\n",
      "\n",
      "6. **Dream Sequence**: The artist might fall asleep at the workbench and enter a vivid dream where the workshop transforms into a fantastical realm, and they have to navigate through it to wake up.\n",
      "\n",
      "Let's go with the magical transformation idea, as it seems quite creative and fits well with the artistic setting.\n",
      "\n",
      "Perhaps the busts start to come to life and engage in a conversation with the artist. The tools begin to move on their own, assisting in creating a new masterpiece. The jars of paint and brushes might start mixing colors autonomously, and the entire workshop becomes a hub of magical creativity.In this scene, as the artist steps back to admire their latest work, something unusual begins to happen. The busts on the shelves start to shift slightly, their stone eyes blinking to life. One by one, they turn their heads and begin to speak, offering critiques and suggestions about the artist's work.\n",
      "\n",
      "Meanwhile, the tools on the workbench start moving on their own, picking themselves up and getting to work. Hammers tap gently, chisels carve with precision, and brushes dip into jars of paint, creating strokes of color without any human guidance. The jars of paint and brushes seem to have a mind of their own, mixing vibrant hues and applying them to canvases and sculptures.\n",
      "\n",
      "The entire workshop transforms into a bustling hub of magical creativity. The artist watches in awe as their workspace comes alive, collaborating with them to create something truly extraordinary. Perhaps this magical event leads to the creation of a masterpiece that transcends the ordinary, blending the artist's vision with the enchanting energy of the workshop.\n",
      "\n",
      "```markdown\n",
      "In this unusual scenario, the busts in the workshop suddenly come to life, engaging in conversation with the artist. The tools begin to move autonomously, assisting in the creation of art. The jars of paint and brushes mix colors and apply them on their own, turning the workshop into a magical hub of creativity. The artist witnesses this enchanting transformation, leading to the creation of a unique and extraordinary masterpiece.\n",
      "```\n",
      "This scene could unfold into a captivating story of art and magic intertwining in unexpected ways.\n"
     ]
    }
   ],
   "source": [
    "TEMP = 0.15\n",
    "MAX_TOK = 100000\n",
    "SYSTEM_PROMPT = load_system_prompt(\"SYSTEM_PROMPT.txt\")\n",
    "# Feel free to replace with any image of your choice!\n",
    "IMAGE_URL = \"https://blogs.nvidia.com/wp-content/uploads/2020/11/marbles-at-night.jpg\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Describe what can happen next in this scene. Be creative and think of an unusual scenario\",\n",
    "            },\n",
    "            {\"type\": \"image_url\", \n",
    "             \"image_url\": {\"url\": IMAGE_URL}\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    temperature=TEMP,\n",
    "    max_tokens=MAX_TOK,\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211da88d-f6c5-48fc-9125-dcced5760ccd",
   "metadata": {},
   "source": [
    "### Function calling\n",
    "\n",
    "Function calling allows the model to generate structured outputs that trigger real functions in your application, turning natural-language queries into executable actions. Instead of returning plain text, the model produces arguments in a predefined schema, enabling you to safely map intent to code paths ‚Äî such as querying a database, retrieving documents, sending notifications, or performing calculations. This turns the model into a reasoning layer that interprets user requests, decides when a tool should be invoked, and returns well-formed call signatures that programs can act on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e2459fc-7762-4c56-beb3-91003336d5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts the interior of a modern, well-equipped commercial kitchen, which doesn't inherently indicate a specific country. However, there are some clues that suggest it might be in **Japan**:\n",
      "\n",
      "1. **Signage and Text**: The writing on the walls appears to be in Japanese.\n",
      "2. **Design and Layout**: The style of the kitchen and the organization is consistent with what you might find in Japanese restaurants or food establishments.\n",
      "\n",
      "These elements suggest that the image is likely from Japan. \n",
      "\n",
      "[ChatCompletionMessageFunctionToolCall(id='chatcmpl-tool-a50c24f1bb90c3fe', function=Function(arguments='{\"country\": \"Japan\", \"unit\": \"millions\"}', name='get_current_population'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "TEMP = 0.15\n",
    "MAX_TOK = 100000\n",
    "IMAGE_URL = \"https://cdna.artstation.com/p/assets/images/images/050/827/584/large/rafael-chies-14.jpg?1655798602\"\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_population\",\n",
    "            \"description\": \"Get the up-to-date population of a given country.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"country\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The country to find the population of.\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The unit for the population.\",\n",
    "                        \"enum\": [\"millions\", \"thousands\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"country\", \"unit\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"rewrite\",\n",
    "            \"description\": \"Rewrite a given text for improved clarity\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The input text to rewrite\",\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Can you tell me which country is shown in this image?\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": IMAGE_URL,\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    temperature=TEMP,\n",
    "    max_tokens=MAX_TOK,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "assistant_message = resp.choices[0].message.content\n",
    "print(assistant_message, \"\\n\")\n",
    "\n",
    "messages.extend([\n",
    "    {\"role\": \"assistant\", \"content\": assistant_message},\n",
    "    {\"role\": \"user\", \"content\": \"What is the population of that country in millions?\"},\n",
    "])\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    temperature=TEMP,\n",
    "    max_tokens=MAX_TOK,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a3fd74-4b7e-41fb-94b3-4d517f61dbfc",
   "metadata": {},
   "source": [
    "## Conclusion and resources\n",
    "\n",
    "Congratulations! You successfully deployed the **Mistral Large 3 675B Instruct** model using vLLM.\n",
    "\n",
    "In this notebook, you have learned how to:\n",
    "\n",
    "- Set up your environment and install vLLM.\n",
    "- Launch and manage an OpenAI-compatible server to run model.\n",
    "- Perform instruction following, vision reasoning, and function calling tasks using the OpenAI client.\n",
    "\n",
    "You can adapt tensor parallelism, ports, and sampling parameters to your hardware and application needs.\n",
    "\n",
    "Refer to the following resources if you want to learn more\n",
    "\n",
    "### Documentation\n",
    "- üìö [Mistral Large 3 Model Card](https://huggingface.co/mistralai/Mistral-Large-3-675B-Instruct-2512)\n",
    "- üèóÔ∏è [NVIDIA vLLM Guide](https://docs.nvidia.com/deeplearning/frameworks/vllm-release-notes/index.html)\n",
    "\n",
    "### Code and kernels\n",
    "- üíæ [Flashinfer kernel library](https://github.com/flashinfer-ai/flashinfer)\n",
    "- ‚ö°  [FlashMLA Implementation](https://github.com/deepseek-ai/FlashMLA)\n",
    "- üß™ [Mistral Examples](https://github.com/mistralai)\n",
    "\n",
    "### Community\n",
    "- üìß [NVIDIA Developer Forums](https://forums.developer.nvidia.com/)\n",
    "\n",
    "### Acknowledgments\n",
    "\n",
    "Special thanks to the Mistral and vLLM teams for their incredible work on these technologies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
